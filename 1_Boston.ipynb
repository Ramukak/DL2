{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "462a1db9",
   "metadata": {},
   "source": [
    "# Assignment 1 \n",
    "## Linear regression by using Deep Neural network\n",
    "\n",
    "Implement Boston housing price \n",
    "prediction problem by Linear regression using Deep Neural network. Use Boston House price prediction dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f803eb12",
   "metadata": {},
   "source": [
    "### Importing and cleaning dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6aaab2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3428e367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
      "57026/57026 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23b093f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train Shape: (404, 13)\n",
      "y_train Shape: (404,)\n",
      "x_test Shape: (102, 13)\n",
      "y_test Shape: (102,)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train Shape:\",x_train.shape)\n",
    "print(\"y_train Shape:\",y_train.shape)\n",
    "print(\"x_test Shape:\",x_test.shape)\n",
    "print(\"y_test Shape:\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec76278c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.23247,   0.     ,   8.14   ,   0.     ,   0.538  ,   6.142  ,\n",
       "        91.7    ,   3.9769 ,   4.     , 307.     ,  21.     , 396.9    ,\n",
       "        18.72   ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62186d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f78040b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = preprocessing.normalize(x_train)\n",
    "x_test = preprocessing.normalize(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6667c75f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0024119 , 0.        , 0.01592969, 0.        , 0.00105285,\n",
       "       0.01201967, 0.17945359, 0.00778265, 0.00782786, 0.6007879 ,\n",
       "       0.04109624, 0.77671895, 0.03663436])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2e586f",
   "metadata": {},
   "source": [
    "### Building linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a305d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ee5df2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hp\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hp\\anaconda3\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               1792      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12161 (47.50 KB)\n",
      "Trainable params: 12161 (47.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential();\n",
    "model.add(Dense(128,activation='relu',input_shape=(x_train[0].shape)))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='rmsprop',loss='mse',metrics=['mae','mse'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2a008c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\hp\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hp\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 556.7125 - mae: 21.7167 - mse: 556.7125 - val_loss: 544.1935 - val_mae: 21.4598 - val_mse: 544.1935\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 466.9805 - mae: 19.5232 - mse: 466.9805 - val_loss: 417.9854 - val_mae: 18.2507 - val_mse: 417.9854\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 324.7141 - mae: 15.3690 - mse: 324.7141 - val_loss: 254.5895 - val_mae: 13.4001 - val_mse: 254.5895\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 178.4525 - mae: 10.0903 - mse: 178.4525 - val_loss: 130.2868 - val_mae: 8.7546 - val_mse: 130.2868\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 102.0778 - mae: 7.1388 - mse: 102.0778 - val_loss: 90.9875 - val_mae: 6.7462 - val_mse: 90.9875\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 86.2231 - mae: 6.6941 - mse: 86.2231 - val_loss: 84.4275 - val_mae: 6.5530 - val_mse: 84.4275\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 82.6940 - mae: 6.5496 - mse: 82.6940 - val_loss: 80.5672 - val_mae: 6.4101 - val_mse: 80.5672\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 79.2481 - mae: 6.4520 - mse: 79.2481 - val_loss: 77.6710 - val_mae: 6.2456 - val_mse: 77.6710\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 76.4796 - mae: 6.2609 - mse: 76.4796 - val_loss: 74.9728 - val_mae: 6.1144 - val_mse: 74.9728\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 74.1215 - mae: 6.0743 - mse: 74.1215 - val_loss: 70.1978 - val_mae: 6.1019 - val_mse: 70.1978\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 71.5805 - mae: 6.0540 - mse: 71.5805 - val_loss: 68.3337 - val_mae: 5.9869 - val_mse: 68.3337\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 69.5827 - mae: 5.9400 - mse: 69.5827 - val_loss: 67.4300 - val_mae: 5.8849 - val_mse: 67.4300\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 67.4845 - mae: 5.8103 - mse: 67.4845 - val_loss: 65.4600 - val_mae: 5.8237 - val_mse: 65.4600\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 66.5293 - mae: 5.7740 - mse: 66.5293 - val_loss: 63.7639 - val_mae: 5.7620 - val_mse: 63.7639\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.9304 - mae: 5.5819 - mse: 64.9304 - val_loss: 63.9807 - val_mae: 6.0431 - val_mse: 63.9807\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 64.4562 - mae: 5.7029 - mse: 64.4562 - val_loss: 60.9732 - val_mae: 5.7117 - val_mse: 60.9732\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 63.8360 - mae: 5.5859 - mse: 63.8360 - val_loss: 60.2521 - val_mae: 5.7414 - val_mse: 60.2521\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.8879 - mae: 5.6681 - mse: 62.8879 - val_loss: 61.1064 - val_mae: 5.6616 - val_mse: 61.1064\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 62.2657 - mae: 5.4723 - mse: 62.2657 - val_loss: 59.1328 - val_mae: 5.6585 - val_mse: 59.1328\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.8554 - mae: 5.4949 - mse: 61.8554 - val_loss: 58.6689 - val_mae: 5.6991 - val_mse: 58.6689\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 60.4184 - mae: 5.4989 - mse: 60.4184 - val_loss: 58.3824 - val_mae: 5.6117 - val_mse: 58.3824\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.3628 - mae: 5.4543 - mse: 61.3628 - val_loss: 58.2110 - val_mae: 5.5981 - val_mse: 58.2110\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.8229 - mae: 5.5289 - mse: 61.8229 - val_loss: 57.8294 - val_mae: 5.5930 - val_mse: 57.8294\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 59.5429 - mae: 5.3784 - mse: 59.5429 - val_loss: 57.3464 - val_mae: 5.6631 - val_mse: 57.3464\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 59.6799 - mae: 5.5013 - mse: 59.6799 - val_loss: 60.5181 - val_mae: 5.6228 - val_mse: 60.5181\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 61.1160 - mae: 5.4269 - mse: 61.1160 - val_loss: 57.2292 - val_mae: 5.5726 - val_mse: 57.2292\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 59.4774 - mae: 5.3789 - mse: 59.4774 - val_loss: 59.5717 - val_mae: 5.5968 - val_mse: 59.5717\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 58.7063 - mae: 5.2700 - mse: 58.7063 - val_loss: 56.9035 - val_mae: 5.6916 - val_mse: 56.9035\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 59.0495 - mae: 5.4162 - mse: 59.0495 - val_loss: 57.3370 - val_mae: 5.5503 - val_mse: 57.3370\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 59.1039 - mae: 5.3374 - mse: 59.1039 - val_loss: 58.0952 - val_mae: 5.5522 - val_mse: 58.0952\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 58.3666 - mae: 5.2960 - mse: 58.3666 - val_loss: 59.3590 - val_mae: 5.5780 - val_mse: 59.3590\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 58.8795 - mae: 5.3222 - mse: 58.8795 - val_loss: 58.9856 - val_mae: 5.5635 - val_mse: 58.9856\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 58.1988 - mae: 5.2186 - mse: 58.1988 - val_loss: 56.9943 - val_mae: 5.5247 - val_mse: 56.9943\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 57.5672 - mae: 5.2204 - mse: 57.5672 - val_loss: 55.5168 - val_mae: 5.5406 - val_mse: 55.5168\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 56.9613 - mae: 5.2236 - mse: 56.9613 - val_loss: 55.4083 - val_mae: 5.5662 - val_mse: 55.4083\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 57.3051 - mae: 5.2469 - mse: 57.3051 - val_loss: 55.8607 - val_mae: 5.4926 - val_mse: 55.8607\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 57.0124 - mae: 5.2094 - mse: 57.0124 - val_loss: 57.1199 - val_mae: 5.5028 - val_mse: 57.1199\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 56.3130 - mae: 5.1328 - mse: 56.3130 - val_loss: 55.2826 - val_mae: 5.4769 - val_mse: 55.2826\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 56.1171 - mae: 5.1687 - mse: 56.1171 - val_loss: 54.7969 - val_mae: 5.4924 - val_mse: 54.7969\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 56.2026 - mae: 5.2428 - mse: 56.2026 - val_loss: 55.2413 - val_mae: 5.4568 - val_mse: 55.2413\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 55.9304 - mae: 5.1594 - mse: 55.9304 - val_loss: 54.9204 - val_mae: 5.4508 - val_mse: 54.9204\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 55.3880 - mae: 5.1031 - mse: 55.3880 - val_loss: 54.4753 - val_mae: 5.4534 - val_mse: 54.4753\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 55.5612 - mae: 5.1445 - mse: 55.5612 - val_loss: 57.6834 - val_mae: 5.4793 - val_mse: 57.6834\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 55.4352 - mae: 5.0199 - mse: 55.4352 - val_loss: 55.1862 - val_mae: 5.4240 - val_mse: 55.1862\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 55.4964 - mae: 5.1044 - mse: 55.4964 - val_loss: 56.3035 - val_mae: 5.4387 - val_mse: 56.3035\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 54.4137 - mae: 5.0230 - mse: 54.4137 - val_loss: 56.3560 - val_mae: 5.4328 - val_mse: 56.3560\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 55.4291 - mae: 4.9987 - mse: 55.4291 - val_loss: 53.8614 - val_mae: 5.4824 - val_mse: 53.8614\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 54.3863 - mae: 5.0929 - mse: 54.3863 - val_loss: 54.1167 - val_mae: 5.3847 - val_mse: 54.1167\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 53.7451 - mae: 5.0046 - mse: 53.7451 - val_loss: 53.5871 - val_mae: 5.3832 - val_mse: 53.5871\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 53.6096 - mae: 5.0328 - mse: 53.6096 - val_loss: 55.4244 - val_mae: 5.3854 - val_mse: 55.4244\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 53.9090 - mae: 4.9055 - mse: 53.9090 - val_loss: 53.1006 - val_mae: 5.3764 - val_mse: 53.1006\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 53.7300 - mae: 4.9741 - mse: 53.7300 - val_loss: 54.5162 - val_mae: 5.5870 - val_mse: 54.5162\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 53.0884 - mae: 5.0232 - mse: 53.0884 - val_loss: 53.0772 - val_mae: 5.3352 - val_mse: 53.0772\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 53.0533 - mae: 4.9229 - mse: 53.0533 - val_loss: 52.9536 - val_mae: 5.3211 - val_mse: 52.9536\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 52.6300 - mae: 4.9779 - mse: 52.6300 - val_loss: 53.8655 - val_mae: 5.3127 - val_mse: 53.8655\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 52.8471 - mae: 4.8775 - mse: 52.8471 - val_loss: 52.2739 - val_mae: 5.3097 - val_mse: 52.2739\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 52.2149 - mae: 4.9868 - mse: 52.2149 - val_loss: 55.6005 - val_mae: 5.3386 - val_mse: 55.6005\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 52.5855 - mae: 4.8968 - mse: 52.5855 - val_loss: 52.0137 - val_mae: 5.3364 - val_mse: 52.0137\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 51.7007 - mae: 4.9110 - mse: 51.7007 - val_loss: 52.0336 - val_mae: 5.2598 - val_mse: 52.0336\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 51.4056 - mae: 4.8658 - mse: 51.4056 - val_loss: 52.1076 - val_mae: 5.3926 - val_mse: 52.1076\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 51.8730 - mae: 4.8692 - mse: 51.8730 - val_loss: 51.2880 - val_mae: 5.2713 - val_mse: 51.2880\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 51.2871 - mae: 4.9050 - mse: 51.2871 - val_loss: 51.4565 - val_mae: 5.2196 - val_mse: 51.4565\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 51.0246 - mae: 4.8916 - mse: 51.0246 - val_loss: 55.0232 - val_mae: 5.2840 - val_mse: 55.0232\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 50.4108 - mae: 4.7566 - mse: 50.4108 - val_loss: 50.7743 - val_mae: 5.2671 - val_mse: 50.7743\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 49.8644 - mae: 4.8121 - mse: 49.8644 - val_loss: 52.0361 - val_mae: 5.1776 - val_mse: 52.0361\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 50.0759 - mae: 4.7851 - mse: 50.0759 - val_loss: 50.7275 - val_mae: 5.1512 - val_mse: 50.7275\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 50.0645 - mae: 4.7581 - mse: 50.0645 - val_loss: 49.9796 - val_mae: 5.1397 - val_mse: 49.9796\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 49.7291 - mae: 4.8272 - mse: 49.7291 - val_loss: 50.8912 - val_mae: 5.1198 - val_mse: 50.8912\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 49.2125 - mae: 4.7288 - mse: 49.2125 - val_loss: 51.3288 - val_mae: 5.1178 - val_mse: 51.3288\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 48.5958 - mae: 4.6461 - mse: 48.5958 - val_loss: 49.1436 - val_mae: 5.1148 - val_mse: 49.1436\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 48.5958 - mae: 4.6969 - mse: 48.5958 - val_loss: 49.3294 - val_mae: 5.0652 - val_mse: 49.3294\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 49.0044 - mae: 4.7189 - mse: 49.0044 - val_loss: 50.2641 - val_mae: 5.0606 - val_mse: 50.2641\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 47.6651 - mae: 4.5746 - mse: 47.6651 - val_loss: 49.2351 - val_mae: 5.0355 - val_mse: 49.2351\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 48.2243 - mae: 4.6237 - mse: 48.2243 - val_loss: 48.1445 - val_mae: 5.0461 - val_mse: 48.1445\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 46.9226 - mae: 4.6255 - mse: 46.9226 - val_loss: 47.8659 - val_mae: 5.0128 - val_mse: 47.8659\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 46.6585 - mae: 4.5803 - mse: 46.6585 - val_loss: 48.5927 - val_mae: 4.9758 - val_mse: 48.5927\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 46.9195 - mae: 4.5889 - mse: 46.9195 - val_loss: 47.3107 - val_mae: 4.9520 - val_mse: 47.3107\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 46.3032 - mae: 4.5681 - mse: 46.3032 - val_loss: 48.1135 - val_mae: 4.9347 - val_mse: 48.1135\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 46.1044 - mae: 4.5194 - mse: 46.1044 - val_loss: 46.4917 - val_mae: 4.9113 - val_mse: 46.4917\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 46.1686 - mae: 4.5763 - mse: 46.1686 - val_loss: 47.0984 - val_mae: 4.8835 - val_mse: 47.0984\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 45.4951 - mae: 4.5014 - mse: 45.4951 - val_loss: 45.8412 - val_mae: 4.8573 - val_mse: 45.8412\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 44.5749 - mae: 4.4338 - mse: 44.5749 - val_loss: 45.5283 - val_mae: 4.8302 - val_mse: 45.5283\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 44.3372 - mae: 4.4588 - mse: 44.3372 - val_loss: 44.9767 - val_mae: 4.8180 - val_mse: 44.9767\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 44.5495 - mae: 4.4771 - mse: 44.5495 - val_loss: 47.1752 - val_mae: 4.8407 - val_mse: 47.1752\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 43.7775 - mae: 4.3942 - mse: 43.7775 - val_loss: 44.3502 - val_mae: 4.7501 - val_mse: 44.3502\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 43.2811 - mae: 4.4413 - mse: 43.2811 - val_loss: 44.7227 - val_mae: 4.7293 - val_mse: 44.7227\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 44.1956 - mae: 4.4476 - mse: 44.1956 - val_loss: 44.0195 - val_mae: 4.6952 - val_mse: 44.0195\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 42.0100 - mae: 4.3342 - mse: 42.0100 - val_loss: 50.2082 - val_mae: 4.9729 - val_mse: 50.2082\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 42.4378 - mae: 4.3695 - mse: 42.4378 - val_loss: 45.0265 - val_mae: 4.7076 - val_mse: 45.0265\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 41.7985 - mae: 4.3235 - mse: 41.7985 - val_loss: 42.9206 - val_mae: 4.6077 - val_mse: 42.9206\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 40.8064 - mae: 4.2975 - mse: 40.8064 - val_loss: 42.0391 - val_mae: 4.6040 - val_mse: 42.0391\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 42.0150 - mae: 4.3524 - mse: 42.0150 - val_loss: 41.6536 - val_mae: 4.5962 - val_mse: 41.6536\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 41.3678 - mae: 4.3130 - mse: 41.3678 - val_loss: 41.4459 - val_mae: 4.5470 - val_mse: 41.4459\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 40.3181 - mae: 4.2160 - mse: 40.3181 - val_loss: 41.2973 - val_mae: 4.5150 - val_mse: 41.2973\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 40.3364 - mae: 4.2346 - mse: 40.3364 - val_loss: 40.6118 - val_mae: 4.4920 - val_mse: 40.6118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 39.7952 - mae: 4.3747 - mse: 39.7952 - val_loss: 45.9576 - val_mae: 4.7276 - val_mse: 45.9576\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 39.8838 - mae: 4.2049 - mse: 39.8838 - val_loss: 39.7118 - val_mae: 4.5204 - val_mse: 39.7118\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 38.7880 - mae: 4.2386 - mse: 38.7880 - val_loss: 39.4498 - val_mae: 4.4101 - val_mse: 39.4498\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 38.1588 - mae: 4.1874 - mse: 38.1588 - val_loss: 38.7106 - val_mae: 4.4417 - val_mse: 38.7106\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 38.4147 - mae: 4.1900 - mse: 38.4147 - val_loss: 39.5126 - val_mae: 4.3659 - val_mse: 39.5126\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x18955c2b2b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=100,verbose=1,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5181e455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[10.125389],\n",
       "       [20.407684],\n",
       "       [23.97695 ],\n",
       "       [24.142025],\n",
       "       [25.005909],\n",
       "       [20.28526 ],\n",
       "       [29.045675],\n",
       "       [26.678694],\n",
       "       [19.04728 ],\n",
       "       [19.22468 ],\n",
       "       [15.596289],\n",
       "       [21.860989],\n",
       "       [17.844017],\n",
       "       [28.875755],\n",
       "       [16.830538],\n",
       "       [24.018372],\n",
       "       [22.441738],\n",
       "       [21.332157],\n",
       "       [18.643295],\n",
       "       [20.48839 ],\n",
       "       [13.803109],\n",
       "       [13.76845 ],\n",
       "       [22.715551],\n",
       "       [20.153765],\n",
       "       [28.229998],\n",
       "       [19.899857],\n",
       "       [25.221197],\n",
       "       [34.995953],\n",
       "       [12.735519],\n",
       "       [23.247078],\n",
       "       [21.698803],\n",
       "       [14.079282],\n",
       "       [30.426462],\n",
       "       [21.774706],\n",
       "       [17.17875 ],\n",
       "       [11.155703],\n",
       "       [15.570353],\n",
       "       [16.03317 ],\n",
       "       [17.911976],\n",
       "       [31.870832],\n",
       "       [26.817776],\n",
       "       [25.347584],\n",
       "       [17.694038],\n",
       "       [26.005962],\n",
       "       [29.510296],\n",
       "       [23.804548],\n",
       "       [29.270218],\n",
       "       [20.159443],\n",
       "       [20.715757],\n",
       "       [22.863987],\n",
       "       [34.441006],\n",
       "       [19.389103],\n",
       "       [14.53022 ],\n",
       "       [18.840647],\n",
       "       [28.567787],\n",
       "       [26.03314 ],\n",
       "       [16.325945],\n",
       "       [29.18125 ],\n",
       "       [31.18213 ],\n",
       "       [24.986818],\n",
       "       [19.595459],\n",
       "       [18.157492],\n",
       "       [14.294364],\n",
       "       [21.373104],\n",
       "       [25.003296],\n",
       "       [30.160858],\n",
       "       [16.23944 ],\n",
       "       [28.748108],\n",
       "       [12.725116],\n",
       "       [12.584055],\n",
       "       [20.22128 ],\n",
       "       [26.053698],\n",
       "       [20.03268 ],\n",
       "       [14.527942],\n",
       "       [25.605158],\n",
       "       [23.328634],\n",
       "       [23.270039],\n",
       "       [22.493916],\n",
       "       [29.634335],\n",
       "       [12.522994],\n",
       "       [22.984821],\n",
       "       [29.95854 ],\n",
       "       [23.204376],\n",
       "       [17.233755],\n",
       "       [22.7127  ],\n",
       "       [20.78607 ],\n",
       "       [18.22704 ],\n",
       "       [20.77551 ],\n",
       "       [23.275892],\n",
       "       [21.62622 ],\n",
       "       [19.930595],\n",
       "       [25.959538],\n",
       "       [25.451834],\n",
       "       [26.5255  ],\n",
       "       [29.50563 ],\n",
       "       [20.26601 ],\n",
       "       [29.908192],\n",
       "       [22.687403],\n",
       "       [21.758024],\n",
       "       [27.23938 ],\n",
       "       [25.887306],\n",
       "       [18.055122]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53023051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.2, 18.8, 19. , 27. , 22.2, 24.5, 31.2, 22.9, 20.5, 23.2, 18.6,\n",
       "       14.5, 17.8, 50. , 20.8, 24.3, 24.2, 19.8, 19.1, 22.7, 12. , 10.2,\n",
       "       20. , 18.5, 20.9, 23. , 27.5, 30.1,  9.5, 22. , 21.2, 14.1, 33.1,\n",
       "       23.4, 20.1,  7.4, 15.4, 23.8, 20.1, 24.5, 33. , 28.4, 14.1, 46.7,\n",
       "       32.5, 29.6, 28.4, 19.8, 20.2, 25. , 35.4, 20.3,  9.7, 14.5, 34.9,\n",
       "       26.6,  7.2, 50. , 32.4, 21.6, 29.8, 13.1, 27.5, 21.2, 23.1, 21.9,\n",
       "       13. , 23.2,  8.1,  5.6, 21.7, 29.6, 19.6,  7. , 26.4, 18.9, 20.9,\n",
       "       28.1, 35.4, 10.2, 24.3, 43.1, 17.6, 15.4, 16.2, 27.1, 21.4, 21.5,\n",
       "       22.4, 25. , 16.6, 18.6, 22. , 42.8, 35.1, 21.5, 36. , 21.9, 24.1,\n",
       "       50. , 26.7, 25. ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f94d58",
   "metadata": {},
   "source": [
    "### Evaluating model performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f96559f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 39.5126 - mae: 4.3659 - mse: 39.5126\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[39.512577056884766, 4.365872383117676, 39.512577056884766]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46bfae0",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    " Loss: 39.5126\n",
    " \n",
    " MAE: 4.3659\n",
    " \n",
    " MSE: 39.5126"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
